{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.exposure import equalize_adapthist\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "import numpy as np\n",
    "# h5py to read the data-set\n",
    "import h5py\n",
    "# matplotlob for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 512\n",
    "im_height = 512\n",
    "border = 5\n",
    "path_train = 'PATH/TO/THE/TRAIN/DATA' \n",
    "path_val = 'PATH/TO/THE/VALIDATION/DATA'\n",
    "path_test = 'PATH/TO/THE/TEST/DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "def get_data(path, train=True):\n",
    "    ids = next(os.walk(path + \"images\"))[2]\n",
    "    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    if train:\n",
    "        y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        # Load images\n",
    "        img = load_img(path + '/images/' + id_, grayscale=True)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (512, 512, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "        # Load masks\n",
    "        if train:\n",
    "            mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n",
    "            mask = resize(mask, (512, 512, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "        # Save images\n",
    "        X[n, ..., 0] = x_img.squeeze() / 255\n",
    "        if train:\n",
    "            y[n] = mask / 255\n",
    "    print('Done!')\n",
    "    if train:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = get_data(path_train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, val_labels = get_data(path_val, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(train_data[0,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(train_labels[0, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(train_data[10, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(train_labels[10, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each block of U-net architecture consist of two Convolution layers\n",
    "# These two layers are written in a function to make our code clean\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The u-net architecture consists of contracting and expansive paths which\n",
    "# shrink and expands the inout image respectivly. \n",
    "# Output image have the same size of input image\n",
    "def get_unet(input_img, n_filters, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*4, kernel_size=3) #The first block of U-net\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*8, kernel_size=3)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*16, kernel_size=3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*32, kernel_size=3)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*64, kernel_size=3)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*32, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*32, kernel_size=3)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*16, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*16, kernel_size=3)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*8, kernel_size=3)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*4, kernel_size=3)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a segmentation task, it is suggested to use dice coefficient instead of accuracy\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    eps = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and Compiling the model\n",
    "input_img = Input((train_data.shape[1], train_data.shape[2], 1), name='img')\n",
    "model = get_unet(input_img, n_filters=2, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[dice_coefficient])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the log and show it by tensorboard\n",
    "NAME='U-Net_Model'\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## early stoping and chekPoint\n",
    "early_stop = EarlyStopping(monitor='val_dice_coefficient', patience=7, mode='max')\n",
    "filepath=\"weights_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_dice_coefficient', verbose=0, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, early_stop,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiting the model \n",
    "results = model.fit(train_data, train_labels, batch_size=3, epochs=150, callbacks=callbacks_list,\n",
    "                    validation_data=(val_data, val_labels),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Test data\n",
    "test_data, test_labels = get_data(path_test, train=True) \n",
    "# If there is no ground-truth for test data, this line should be written test_data = get_data(path_test, train=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a mask for test images\n",
    "preds_test = model.predict(test_data, verbose=1)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8) # thresholding (should be between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of test image and the predicted mask\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_data[0,:,:,0], cmap=plt.get_cmap('gray'))\n",
    "##### should be commented if no ground-truth for test data##### \n",
    "plt.subplot(222)\n",
    "plt.imshow(test_labels[0, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "########################################################\n",
    "plt.subplot(223)\n",
    "plt.imshow(preds_test[0, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(preds_test_t[0, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
